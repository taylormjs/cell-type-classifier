---
layout: default
title: 'Background'
---

### Background

The past decade has seen the development of numerous experimental methods to generate data at single-cell resolution. Single-cell datasets have made it possible to better characterize individual cells by their cell type and cell state \cite{integrative-singe-cell, abdelaal}. Similarly, improved understanding in differences between single-cells has allowed researchers to better define the features inherent to each cell type \cite{eleven-challenges}. Finding these single-cell molecular profiles for cell-type identification has been the main goal of creating a Human Cell Atlas, an international collaborative effort to characterize every cell in the human body. \cite{regev_human_cell_atlas}. While most of the characterization has relied on scRNA-seq data to measure transcriptional differences, other data types have measured chromatin accessibility, methylation levels, protein levels, spatial information, and other data modalities. \cite{eleven-challenges}.  \\

Only recently have efforts been made to generate multimodal single-cell datasets in which multiple data types are produced for the same cell (e.g. mRNA + DNA methylation data) \cite{integrative-single-cell} \cite{sci-CAR}. Much work remains for understanding the power of using multimodal data for cell-type and cell-state classification.  It's also unclear how features from multimodal single-cell inform a cell's molecular profile. For example, a bimodal single-cell dataset containing information on gene expression and chromatin accessibility may better characterize a cell, but it's unclear whether features from gene expression or chromatin accessibility are more informative for its identification. \\

Beyond genomics, multimodal machine learning is a blossoming field vying to understand how to best represent multimodal inputs and fuse multiple modalities to bolster predictive power. \cite{multimodal-ml}. Numerous multimodal studies have been done in other fields such as speech recognition, event detection, emotion recognition, and media description. \cite{multimodal-ml}. However, multimodal learning is still very new to the world of single-cell genomics \cite{integrative-singe-cell}, allowing for many new potential applications. \\

Deep learning has also just entered the world of single-cell genomics, specifically in identifying cell types and cell states. Other deep learning approaches for cell-type classification such as  \cite{ma_actinn_2020} and \cite{lopez_deep_2018} do exist and ought to be leveraged, yet these use only one modality as input. Multimodal classification has been used in healthcare such as in \cite{pancancer} as well as analyzing PATCH-seq data such as in \cite{patch-seq} \cite{coupled-autoencoders}, yet none of these methods use deep learning for analyzing high-dimensional multi-modal genomics data. \\
