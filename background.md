---
layout: default
title: 'Background'
---

### Background

The past decade has seen the development of numerous experimental methods to generate data at single-cell resolution. Single-cell datasets have made it possible to better characterize individual cells by their cell type and cell state. Similarly, improved understanding in differences between single-cells has allowed researchers to better define the features inherent to each cell type. Finding these single-cell molecular profiles for cell-type identification has been the main goal of creating a Human Cell Atlas, an international collaborative effort to characterize every cell in the human body. While most of the characterization has relied on scRNA-seq data to measure transcriptional differences, other data types have measured chromatin accessibility, methylation levels, protein levels, spatial information, and other data modalities.  

Only recently have efforts been made to generate multimodal single-cell datasets in which multiple data types are produced for the same cell (e.g. mRNA + DNA methylation data). Much work remains for understanding the power of using multimodal data for cell-type and cell-state classification.  It's also unclear how features from multimodal single-cell inform a cell's molecular profile. For example, a bimodal single-cell dataset containing information on gene expression and chromatin accessibility may better characterize a cell, but it's unclear whether features from gene expression or chromatin accessibility are more informative for its identification. 

Beyond genomics, multimodal machine learning is a blossoming field vying to understand how to best represent multimodal inputs and fuse multiple modalities to bolster predictive power.. Numerous multimodal studies have been done in other fields such as speech recognition, event detection, emotion recognition, and media description.. However, multimodal learning is still very new to the world of single-cell genomics, allowing for many new potential applications. 

Deep learning has also just entered the world of single-cell genomics, specifically in identifying cell types and cell states. Other deep learning approaches for cell-type classification such as  and do exist and ought to be leveraged, yet these use only one modality as input. Multimodal classification has been used in healthcare such as in as well as analyzing PATCH-seq data such as in, yet none of these methods use deep learning for analyzing high-dimensional multi-modal genomics data. 


# TODO - include references and potentially images
