{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Sufficient Input Subsets to Trained Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook will apply SIS to understand which subsets of features from ATAC-seq, RNA-seq, and the bimodal input are most needed to maintain similar classification results. These subsets are desirable for the following reasons:**\n",
    "- 1. For the bimodal input, they suggest which of the features from ATAC-seq and RNA-seq are most needed. Theoretically, these two modalities contain the same information and RNA-seq may be able to contain the same (and more) information than ATAC-seq. We expect the majority of the features in these subsets to come from RNA-seq features, precluding the need for multimodal data in classification. However, ATAC-seq may contain features that RNA-seq doesn't capture\n",
    "- 2. These subsets may suggest marker genes for a given cell type, which would we be useful for the Human Cell Atlas and any other project aiming to identify and describe cell types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "- SIS paper: https://arxiv.org/pdf/1810.03805.pdf\n",
    "- GITHUB with more details: https://github.com/b-carter/SufficientInputSubsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### SIS applied to a CNN trained on MNIST: (modify this for our project)\n",
    "- Found this here: https://github.com/google-research/google-research/blob/master/sufficient_input_subsets/tutorials/sis_mnist_tutorial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'google-research' already exists and is not an empty directory.\n",
      "/Users/tjamesso/Desktop/MIT Courses/6_874_DL/Project/6_874-Multimodal-DL/google-research\n"
     ]
    }
   ],
   "source": [
    "# Install sufficient input subsets from Google Research '''\n",
    "\n",
    "# uncomment the following lines to install sufficient_input_subsets\n",
    "!git clone https://github.com/google-research/google-research.git\n",
    "%cd google-research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess imported\n",
      "module name : helpers module package: \n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sufficient_input_subsets import sis\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIS for our cell-state classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Include code below ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle files read\n"
     ]
    }
   ],
   "source": [
    "# Load training and test data from pkl files\n",
    "\n",
    "# get file paths\n",
    "root = os.path.split(os.getcwd())[0]\n",
    "pkl_path = os.path.join(root, 'data', 'sci-CAR', 'pkl_files')\n",
    "pkl_atac = os.path.join(pkl_path, 'atac_pp_svd_fs_.pkl')\n",
    "pkl_rna = os.path.join(pkl_path, 'rna_pp_fs_pca_.pkl')\n",
    "pkl_bimodal = os.path.join(pkl_path, 'bimodal_pp_fs.pkl')\n",
    "pkl_bi_low = os.path.join(pkl_path, 'bimodal_factor20_pp_fs.pkl')\n",
    "\n",
    "# read pickle files\n",
    "atac_train, atac_test, atac_features = read_pickle(pkl_atac)\n",
    "rna_train, rna_test, rna_features = read_pickle(pkl_rna)\n",
    "bimodal_train, bimodal_test, bimodal_features = read_pickle(pkl_bimodal)\n",
    "bi_low_train, bi_low_test, bi_low_features = read_pickle(pkl_bi_low)\n",
    "\n",
    "print('pickle files read')\n",
    "\n",
    "# convert tensors to numpy arrays\n",
    "atac_train_np, atac_test_np = atac_train.numpy(), atac_test.numpy()\n",
    "rna_train_np, rna_test_np = rna_train.numpy(), rna_test.numpy()\n",
    "bimodal_train_np, bimodal_test_np = bimodal_train.numpy(), bimodal_test.numpy()\n",
    "bi_low_train_np, bi_low_test_np = bi_low_train.numpy(), bi_low_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2376, 50]), TensorShape([2376, 30]), TensorShape([2376, 53946]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atac_train.shape, rna_train.shape, bimodal_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the masks (mean values of each training set)\n",
    "\n",
    "# get the num of features in each matrix\n",
    "n_atac_features = atac_train.shape[1]\n",
    "n_rna_features = rna_train.shape[1]\n",
    "n_bimodal_features = bimodal_train.shape[1]\n",
    "n_bi_low_features = bi_low_train.shape[1]\n",
    "\n",
    "\n",
    "# Following the SIS paper, we use the mean pixel from training data as a mask.\n",
    "ATAC_MASK = np.full((n_atac_features, 1), np.mean(atac_train_np))\n",
    "RNA_MASK = np.full((n_rna_features, 1), np.mean(rna_train_np))\n",
    "BIMODAL_MASK = np.full((n_bimodal_features, 1), np.mean(bimodal_train_np))\n",
    "BI_LOW_MASK = np.full((n_bi_low_features, 1), np.mean(bi_low_train_np))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "30\n",
      "53946\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(n_atac_features)\n",
    "print(n_rna_features)\n",
    "print(n_bimodal_features)\n",
    "print(n_bi_low_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.split(os.getcwd())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models loaded\n"
     ]
    }
   ],
   "source": [
    "# Load the models\n",
    "\n",
    "# get directories\n",
    "atac_model_dir = os.path.join(root, 'models', 'best_atac_pca_model_pp_fs')\n",
    "rna_model_dir = os.path.join(root, 'models', 'best_rna_pca_model_pp_fs')\n",
    "bimodal_model_dir = os.path.join(root, 'models', 'best_bimodal_model_pp_fs')\n",
    "bi_low_model_dir = os.path.join(root, 'models', 'best_factor2_model_pp_fs')\n",
    "\n",
    "\n",
    "# load models\n",
    "atac_model  = K.models.load_model(atac_model_dir)\n",
    "rna_model  = K.models.load_model(rna_model_dir)\n",
    "bimodal_model = K.models.load_model(bimodal_model_dir)\n",
    "bi_low_model = K.models.load_model(bi_low_model_dir)\n",
    "\n",
    "print('models loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "HOURS = 2 # choose from [0, 1, 2] which corresponds to [0hr, 1hr, 3hr]\n",
    "THRESHOLD = 0.7  #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "MODEL = bimodal_model\n",
    "TEST_SET = bimodal_test_np\n",
    "MASK = BIMODAL_MASK\n",
    "FEATURE_VEC = bimodal_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function that selects the probability for a single class, from the\n",
    "# softmax output.\n",
    "def make_f_for_digit(digit, model):\n",
    "    def f_digit(batch_of_inputs):\n",
    "        return model.predict(\n",
    "            batch_of_inputs,\n",
    "            batch_size=min(784, len(batch_of_inputs)))[:, digit]\n",
    "    return f_digit\n",
    "\n",
    "# This function maps a list of images to a list of probabilities (probability of\n",
    "# each image being a 4).\n",
    "f_digit = make_f_for_digit(HOURS, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function that filters input images to those the model predicts with\n",
    "# high confidence (f(image) >= threshold).\n",
    "def select_images_for_sis(inputs, f_digit, threshold, upper=1.0):\n",
    "    preds = f_digit(inputs)\n",
    "    idxs = np.nonzero(preds >= threshold)[0]\n",
    "    return inputs[idxs], preds[idxs]\n",
    "\n",
    "# Filter test images that the model classifies as 4 with high confidence.\n",
    "high_confidence_cells = select_images_for_sis(TEST_SET, f_digit,\n",
    "                                                         THRESHOLD, upper=.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 105 cells >= 0.7 confidence\n"
     ]
    }
   ],
   "source": [
    "# take a look at the samples and predictions classified with high confidence\n",
    "\n",
    "hc_samples, hc_preds = high_confidence_cells\n",
    "print(f'Found {hc_preds.shape[0]} cells >= {THRESHOLD} confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select some of these digits to run SIS.\n",
    "cells_to_run_sis = hc_samples[\n",
    "    np.random.choice(hc_samples.shape[0],\n",
    "                     size=5,\n",
    "                     replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR run all cells through SIS\n",
    "cells_to_run_sis = tf.convert_to_tensor(high_confidence_cells[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run SIS on each digit and visualize the resulting SIS-collections.\n",
    "begin = time.time()\n",
    "collections = []\n",
    "for initial_cell in cells_to_run_sis:\n",
    "    begin_loop = time.time()\n",
    "    collection = sis.sis_collection(f_digit, THRESHOLD, initial_cell,\n",
    "                                    np.squeeze(MASK))\n",
    "    collections.append(collection)\n",
    "    end_loop = time.time()\n",
    "    print(f'Loop completed in {end_loop - begin_loop}')\n",
    "end = time.time()\n",
    "#     plot_sis_collection(initial_image, collection, FULLY_MASKED_IMAGE)\n",
    "print(f'Cell complete in {end-begin} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIS Output Analysis\n",
    "Each SIS Output comes as an interable of length 4 with the following entries:\n",
    "0. sis: Sufficient input subset, ordered by most important features\n",
    "1. The order of features removed by back selection -- the most important features are at the end\n",
    "2. The resulting probabilities if you remove up to that feature\n",
    "3. Mask (probably not important for this analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze collections\n",
    "def get_features_from_ixs(ix, feature_vec):\n",
    "    return feature_vec[ix].to_numpy()\n",
    "\n",
    "\n",
    "# Get all subsets into a nice dataframe\n",
    "def get_features_from_collection(collection, feature_vec):\n",
    "    features_mat = []\n",
    "    for ix, cell in enumerate(collection):\n",
    "        for disjoint_subset in cell:\n",
    "            sis_ixs = disjoint_subset[0]\n",
    "            features = get_features_from_ixs(sis_ixs, feature_vec)\n",
    "            features_mat.append((ix, features))\n",
    "    return features_mat\n",
    "\n",
    "\n",
    "# get a list of most important features\n",
    "important_features = get_features_from_collection(collections, FEATURE_VEC)\n",
    "\n",
    "\n",
    "classes = ['0hr', '1hr', '3hr']\n",
    "\n",
    "def print_features(important_features, class_, dataset):\n",
    "    print('_'*100)\n",
    "    print(f'Dataset: {dataset}')\n",
    "    print(f'Num cells above threshold : {len(cells_to_run_sis)}')\n",
    "    print(f'Important features to classify as {class_}')\n",
    "    print(count_genes(important_features))\n",
    "    print('_'*100)\n",
    "    for row in important_features:\n",
    "        print(f'Cell {row[0]} Disjoint SIS: {[g[0] for g in row[1]]}')\n",
    "        \n",
    "# get a print out of the important features\n",
    "print_features(important_features, class_=classes[HOURS], dataset='Bimodal 30 RNA-seq PCs, 50 ATAC-seq SVs from sci-CAR')\n",
    "        \n",
    "\n",
    "def count_genes(important_features):\n",
    "    gene_dict = {}\n",
    "    for ix, features in important_features:\n",
    "        for f in features:\n",
    "            if f[0] not in gene_dict:\n",
    "                gene_dict[f[0]] = 1\n",
    "            else:\n",
    "                gene_dict[f[0]] += 1\n",
    "    # sort gene dict\n",
    "    return gene_dict\n",
    "\n",
    "count_genes(important_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return sorted list of gene counts\n",
    "data = count_genes(important_features), important_features\n",
    "write_zipped_pickle(data, filename=os.path.join(root, 'results', 'initial_model_pp_fs_scai', f'Bimodal_Full_class_{classes[HOURS]}_SIS_thresh={THRESHOLD}.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Reference code from Google Research -- running SIS on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Select a digit and threshold {run: \"auto\"}\n",
    "\n",
    "DIGIT = 4  #@param ['0', 1', '2', '3', '4', '5', '6', '7', '8', '9'] {type:\"raw\"}\n",
    "\n",
    "THRESHOLD = 0.7  #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "\n",
    "# Following the SIS paper, we use the mean pixel from training images as a mask.\n",
    "FULLY_MASKED_IMAGE = np.full((28, 28, 1), np.mean(x_train))\n",
    "\n",
    "# Helper function that selects the probability for a single class, from the\n",
    "# softmax output.\n",
    "def make_f_for_digit(digit, model):\n",
    "    def f_digit(batch_of_inputs):\n",
    "        return model.predict(\n",
    "            batch_of_inputs,\n",
    "            batch_size=min(784, len(batch_of_inputs)))[:, digit]\n",
    "    return f_digit\n",
    "\n",
    "# This function maps a list of images to a list of probabilities (probability of\n",
    "# each image being a 4).\n",
    "f_digit = make_f_for_digit(DIGIT, model)\n",
    "\n",
    "# Helper function that filters input images to those the model predicts with\n",
    "# high confidence (f(image) >= threshold).\n",
    "def select_images_for_sis(inputs, f_digit, threshold):\n",
    "    preds = f_digit(inputs)\n",
    "    idxs = np.nonzero(preds >= threshold)[0]\n",
    "    return inputs[idxs]\n",
    "\n",
    "# Filter test images that the model classifies as 4 with high confidence.\n",
    "high_confidence_images_for_digit = select_images_for_sis(x_test, f_digit,\n",
    "                                                         THRESHOLD)\n",
    "\n",
    "# Randomly select some of these digits to run SIS.\n",
    "digits_to_run_sis = high_confidence_images_for_digit[\n",
    "    np.random.choice(high_confidence_images_for_digit.shape[0],\n",
    "                     size=5,\n",
    "                     replace=False)]\n",
    "\n",
    "# Helpers for plotting an MNIST digit and its corresponding SIS-collection.\n",
    "def plot_mnist_digit(ax, image):\n",
    "    ax.imshow(image[:, :, 0], cmap=plt.get_cmap('gray'))\n",
    "    ax.axis('off')\n",
    "\n",
    "def plot_sis_collection(initial_image, collection, fully_masked_image):\n",
    "    # Grid contains initial image, an empty cell (for spacing), and collection.\n",
    "    width = len(collection) + 2\n",
    "    plt.figure(figsize=(width, 1))\n",
    "    gs = plt.GridSpec(1, width, wspace=0.1)\n",
    "\n",
    "    # Plot initial image.\n",
    "    ax = plt.subplot(gs[0])\n",
    "    plot_mnist_digit(ax, initial_image)\n",
    "\n",
    "    # Plot each SIS.\n",
    "    for i, sis_result in enumerate(collection):\n",
    "        ax = plt.subplot(gs[i+2])\n",
    "        masked_image = sis.produce_masked_inputs(\n",
    "            initial_image, fully_masked_image, [sis_result.mask])[0]\n",
    "        plot_mnist_digit(ax, masked_image)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "print('Running SIS on {} examples of digit {}. '\n",
    "      'This might take a couple minutes.'.format(len(digits_to_run_sis), DIGIT))\n",
    "\n",
    "# Run SIS on each digit and visualize the resulting SIS-collections.\n",
    "for initial_image in digits_to_run_sis:\n",
    "    collection = sis.sis_collection(f_digit, THRESHOLD, initial_image,\n",
    "                                    FULLY_MASKED_IMAGE)\n",
    "    plot_sis_collection(initial_image, collection, FULLY_MASKED_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
