{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Sufficient Input Subsets to Trained Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook will apply SIS to understand which subsets of features from ATAC-seq, RNA-seq, and the bimodal input are most needed to maintain similar classification results. These subsets are desirable for the following reasons:**\n",
    "- 1. For the bimodal input, they suggest which of the features from ATAC-seq and RNA-seq are most needed. Theoretically, these two modalities contain the same information and RNA-seq may be able to contain the same (and more) information than ATAC-seq. We expect the majority of the features in these subsets to come from RNA-seq features, precluding the need for multimodal data in classification. However, ATAC-seq may contain features that RNA-seq doesn't capture\n",
    "- 2. These subsets may suggest marker genes for a given cell type, which would we be useful for the Human Cell Atlas and any other project aiming to identify and describe cell types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "- SIS paper: https://arxiv.org/pdf/1810.03805.pdf\n",
    "- GITHUB with more details: https://github.com/b-carter/SufficientInputSubsets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### SIS applied to a CNN trained on MNIST: (modify this for our project)\n",
    "- Found this here: https://github.com/google-research/google-research/blob/master/sufficient_input_subsets/tutorials/sis_mnist_tutorial.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'google-research' already exists and is not an empty directory.\n",
      "/Users/tjamesso/Desktop/MIT Courses/6_874_DL/Project/6_874-Multimodal-DL/google-research\n"
     ]
    }
   ],
   "source": [
    "# Install sufficient input subsets from Google Research '''\n",
    "\n",
    "# uncomment the following lines to install sufficient_input_subsets\n",
    "!git clone https://github.com/google-research/google-research.git\n",
    "%cd google-research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocess imported\n",
      "module name : helpers module package: \n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "from sufficient_input_subsets import sis\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIS for our cell-state classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Include code below ##########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pickle files read\n"
     ]
    }
   ],
   "source": [
    "# Load training and test data from pkl files\n",
    "\n",
    "# get file paths\n",
    "root = os.path.split(os.getcwd())[0]\n",
    "pkl_path = os.path.join(root, 'data', 'sci-CAR', 'pkl_files')\n",
    "pkl_atac = os.path.join(pkl_path, 'atacRaw_upSampled.pkl')\n",
    "pkl_rna = os.path.join(pkl_path, 'rnaRaw_upSampled.pkl')\n",
    "pkl_bimodal = os.path.join(pkl_path, 'bimodalRaw_upSampled.pkl')\n",
    "pkl_bi_low = os.path.join(pkl_path, 'bimodal_cellLoad_upSampled.pkl')\n",
    "\n",
    "# read pickle files\n",
    "atac_train, atac_test, atac_features = read_pickle(pkl_atac)\n",
    "rna_train, rna_test, rna_features = read_pickle(pkl_rna)\n",
    "bimodal_train, bimodal_test, bimodal_features = read_pickle(pkl_bimodal)\n",
    "bi_low_train, bi_low_test, bi_low_features = read_pickle(pkl_bi_low)\n",
    "\n",
    "print('pickle files read')\n",
    "\n",
    "# convert tensors to numpy arrays\n",
    "atac_train_np, atac_test_np = atac_train.numpy(), atac_test.numpy()\n",
    "rna_train_np, rna_test_np = rna_train.numpy(), rna_test.numpy()\n",
    "bimodal_train_np, bimodal_test_np = bimodal_train.numpy(), bimodal_test.numpy()\n",
    "bi_low_train_np, bi_low_test_np = bi_low_train.numpy(), bi_low_test.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2582, 52761]),\n",
       " TensorShape([2582, 1185]),\n",
       " TensorShape([2582, 53946]),\n",
       " TensorShape([2902, 20]))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atac_train.shape, rna_train.shape, bimodal_train.shape, bi_low_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the masks (mean values of each training set)\n",
    "\n",
    "# get the num of features in each matrix\n",
    "n_atac_features = atac_train.shape[1]\n",
    "n_rna_features = rna_train.shape[1]\n",
    "n_bimodal_features = bimodal_train.shape[1]\n",
    "n_bi_low_features = bi_low_train.shape[1]\n",
    "\n",
    "\n",
    "# Following the SIS paper, we use the mean pixel from training data as a mask.\n",
    "ATAC_MASK = np.full((n_atac_features, 1), np.mean(atac_train_np))\n",
    "RNA_MASK = np.full((n_rna_features, 1), np.mean(rna_train_np))\n",
    "BIMODAL_MASK = np.full((n_bimodal_features, 1), np.mean(bimodal_train_np))\n",
    "BI_LOW_MASK = np.full((n_bi_low_features, 1), np.mean(bi_low_train_np))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52761\n",
      "1185\n",
      "53946\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(n_atac_features)\n",
    "print(n_rna_features)\n",
    "print(n_bimodal_features)\n",
    "print(n_bi_low_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.split(os.getcwd())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models loaded\n"
     ]
    }
   ],
   "source": [
    "# Load the models\n",
    "\n",
    "# get directories\n",
    "atac_model_dir = os.path.join(root, 'models', 'Archive', 'best_atacRaw_upSampled_model')\n",
    "rna_model_dir = os.path.join(root, 'models', 'Archive', 'best_rnaRaw_upSampled_model')\n",
    "bimodal_model_dir = os.path.join(root, 'models', 'Archive', 'best_bimodal_upSampled_model')\n",
    "bi_low_model_dir = os.path.join(root, 'models', 'Archive', 'best_bimodal_cellLoad_upSampled_model')\n",
    "\n",
    "\n",
    "# load models\n",
    "atac_model  = K.models.load_model(atac_model_dir)\n",
    "rna_model  = K.models.load_model(rna_model_dir)\n",
    "bimodal_model = K.models.load_model(bimodal_model_dir)\n",
    "bi_low_model = K.models.load_model(bi_low_model_dir)\n",
    "\n",
    "print('models loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "HOURS = 2 # choose from [0, 1, 2] which corresponds to [0hr, 1hr, 3hr]\n",
    "THRESHOLD = 0.7  #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "MODEL = rna_model\n",
    "TEST_SET = rna_test_np\n",
    "MASK = RNA_MASK\n",
    "FEATURE_VEC = rna_features\n",
    "TITLE = 'RNA Raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "THRESHOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function that selects the probability for a single class, from the\n",
    "# softmax output.\n",
    "def make_f_for_digit(digit, model):\n",
    "    def f_digit(batch_of_inputs):\n",
    "        return model.predict(\n",
    "            batch_of_inputs,\n",
    "            batch_size=min(784, len(batch_of_inputs)))[:, digit]\n",
    "    return f_digit\n",
    "\n",
    "# This function maps a list of images to a list of probabilities (probability of\n",
    "# each image being a 4).\n",
    "f_digit = make_f_for_digit(HOURS, MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function that filters input images to those the model predicts with\n",
    "# high confidence (f(image) >= threshold).\n",
    "def select_images_for_sis(inputs, f_digit, threshold):\n",
    "    preds = f_digit(inputs)\n",
    "    idxs = np.nonzero(preds >= threshold)[0]\n",
    "    return inputs[idxs], preds[idxs]\n",
    "\n",
    "# Filter test images that the model classifies as 4 with high confidence.\n",
    "high_confidence_cells = select_images_for_sis(TEST_SET, f_digit,\n",
    "                                                         THRESHOLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 103 cells >= 0.7 confidence\n"
     ]
    }
   ],
   "source": [
    "# take a look at the samples and predictions classified with high confidence\n",
    "\n",
    "hc_samples, hc_preds = high_confidence_cells\n",
    "print(f'Found {hc_preds.shape[0]} cells >= {THRESHOLD} confidence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9976012 , 0.96586925, 0.9993926 , 0.99842477, 0.9998272 ,\n",
       "       0.99827373, 0.99877816, 0.9998398 , 0.9948368 , 0.9978096 ,\n",
       "       0.8405217 , 0.9996517 , 0.7881396 , 0.9998242 , 0.99765766,\n",
       "       0.99863845, 0.9931543 , 0.9950682 , 0.99349517, 0.99988425,\n",
       "       0.99986684, 0.99932146, 0.9993299 , 0.99999833, 0.9967277 ,\n",
       "       0.7025534 , 0.99702793, 0.9999447 , 0.9981192 , 0.9988502 ,\n",
       "       0.9913591 , 0.99999726, 0.9998596 , 0.999694  , 0.9991084 ,\n",
       "       0.91017216, 0.9685043 , 0.99781585, 0.9981871 , 0.98401225,\n",
       "       0.9999182 , 0.9995876 , 0.81144524, 0.7733769 , 0.9862895 ,\n",
       "       0.99928856, 0.9996793 , 0.9989491 , 0.99851197, 0.9957625 ,\n",
       "       0.8860866 , 0.78436047, 0.9995573 , 0.9988908 , 0.9996855 ,\n",
       "       0.99999297, 0.9997377 , 0.9974618 , 0.99632794, 0.9996006 ,\n",
       "       0.9995221 , 0.859427  , 0.9908602 , 0.99588984, 0.9998354 ,\n",
       "       0.9993368 , 0.8837964 , 0.999998  , 0.9961836 , 0.95274043,\n",
       "       0.9996762 , 0.9966247 , 0.999126  , 0.99093306, 0.9998535 ,\n",
       "       0.7824813 , 0.99969816, 0.99993145, 0.9994677 , 0.99200857,\n",
       "       0.74230266, 0.9871055 , 0.97554547, 0.9937051 , 0.99996734,\n",
       "       0.9999622 , 0.99753976, 0.98252136, 0.9923694 , 0.9945234 ,\n",
       "       0.99869365, 0.9979672 , 0.94636863, 0.9934223 , 0.985282  ,\n",
       "       0.9997615 , 0.9942181 , 0.9998467 , 0.9998184 , 0.9951886 ,\n",
       "       0.99989116, 0.99157166, 0.9987519 ], dtype=float32)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hc_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Randomly select some of these digits to run SIS.\n",
    "# cells_to_run_sis = hc_samples[\n",
    "#     np.random.choice(hc_samples.shape[0],\n",
    "#                      size=5,\n",
    "#                      replace=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OR run all cells through SIS\n",
    "cells_to_run_sis = tf.convert_to_tensor(high_confidence_cells[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loop completed in 25.36620593070984\n",
      "Loop completed in 23.25635313987732\n",
      "Loop completed in 23.580237865447998\n",
      "Loop completed in 26.5559139251709\n",
      "Loop completed in 24.454350233078003\n",
      "Loop completed in 23.697070121765137\n",
      "Loop completed in 23.95415687561035\n",
      "Loop completed in 26.453312158584595\n",
      "Loop completed in 22.88639998435974\n",
      "Loop completed in 22.92171311378479\n",
      "Loop completed in 22.813381910324097\n",
      "Loop completed in 22.54314374923706\n",
      "Loop completed in 24.342291831970215\n",
      "Loop completed in 22.770493745803833\n",
      "Loop completed in 22.46404504776001\n",
      "Loop completed in 22.618826866149902\n",
      "Loop completed in 24.66104292869568\n",
      "Loop completed in 26.004273176193237\n",
      "Loop completed in 24.972266912460327\n",
      "Loop completed in 22.396268129348755\n",
      "Loop completed in 23.614142179489136\n",
      "Loop completed in 22.15380597114563\n",
      "Loop completed in 23.419946670532227\n",
      "Loop completed in 23.61780285835266\n",
      "Loop completed in 24.359530925750732\n",
      "Loop completed in 23.04483199119568\n",
      "Loop completed in 23.00208830833435\n",
      "Loop completed in 23.26003384590149\n",
      "Loop completed in 25.352926015853882\n",
      "Loop completed in 22.871720790863037\n",
      "Loop completed in 22.970082759857178\n",
      "Loop completed in 22.94351315498352\n",
      "Loop completed in 24.35842990875244\n",
      "Loop completed in 22.78975796699524\n",
      "Loop completed in 23.300820112228394\n",
      "Loop completed in 23.615532875061035\n",
      "Loop completed in 24.676671981811523\n",
      "Loop completed in 23.15048122406006\n",
      "Loop completed in 23.46057391166687\n",
      "Loop completed in 22.60858702659607\n",
      "Loop completed in 22.432251930236816\n",
      "Loop completed in 23.547605991363525\n",
      "Loop completed in 22.65521001815796\n",
      "Loop completed in 22.620718717575073\n",
      "Loop completed in 22.89731001853943\n",
      "Loop completed in 25.031049013137817\n",
      "Loop completed in 23.621174097061157\n",
      "Loop completed in 22.761785984039307\n",
      "Loop completed in 22.626507997512817\n",
      "Loop completed in 23.39903473854065\n",
      "Loop completed in 23.277899980545044\n",
      "Loop completed in 22.911203145980835\n",
      "Loop completed in 22.514517068862915\n",
      "Loop completed in 24.10609221458435\n",
      "Loop completed in 21.953056812286377\n",
      "Loop completed in 22.130346059799194\n",
      "Loop completed in 22.075416088104248\n",
      "Loop completed in 23.125341176986694\n",
      "Loop completed in 21.913686990737915\n",
      "Loop completed in 22.221166133880615\n",
      "Loop completed in 21.984223127365112\n",
      "Loop completed in 23.127667903900146\n",
      "Loop completed in 22.19181203842163\n",
      "Loop completed in 22.35704803466797\n",
      "Loop completed in 22.110886096954346\n",
      "Loop completed in 24.55402398109436\n",
      "Loop completed in 24.58498191833496\n",
      "Loop completed in 22.486888885498047\n",
      "Loop completed in 22.920662879943848\n",
      "Loop completed in 25.031687021255493\n",
      "Loop completed in 22.94806408882141\n",
      "Loop completed in 22.29475498199463\n",
      "Loop completed in 22.943882942199707\n",
      "Loop completed in 24.245476722717285\n",
      "Loop completed in 23.98729705810547\n",
      "Loop completed in 23.16355013847351\n",
      "Loop completed in 23.236889123916626\n",
      "Loop completed in 23.209470987319946\n",
      "Loop completed in 24.199727773666382\n",
      "Loop completed in 23.028208017349243\n",
      "Loop completed in 24.61532473564148\n",
      "Loop completed in 23.047004222869873\n",
      "Loop completed in 23.745417833328247\n",
      "Loop completed in 22.74337100982666\n",
      "Loop completed in 22.398669004440308\n",
      "Loop completed in 22.82970404624939\n",
      "Loop completed in 23.674386978149414\n",
      "Loop completed in 22.81459379196167\n",
      "Loop completed in 23.15730118751526\n",
      "Loop completed in 23.235831022262573\n",
      "Loop completed in 24.25874900817871\n",
      "Loop completed in 22.858263731002808\n",
      "Loop completed in 23.19645619392395\n",
      "Loop completed in 22.903302907943726\n",
      "Loop completed in 24.09283185005188\n",
      "Loop completed in 22.55863332748413\n",
      "Loop completed in 22.86872410774231\n",
      "Loop completed in 23.05141019821167\n",
      "Loop completed in 23.94961404800415\n",
      "Loop completed in 22.76358199119568\n",
      "Loop completed in 23.333070993423462\n",
      "Loop completed in 23.41219997406006\n",
      "Loop completed in 22.884845733642578\n",
      "Cell complete in 2404.1381027698517 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run SIS on each digit and visualize the resulting SIS-collections.\n",
    "begin = time.time()\n",
    "collections = []\n",
    "for initial_cell in cells_to_run_sis:\n",
    "    begin_loop = time.time()\n",
    "    collection = sis.sis_collection(f_digit, THRESHOLD, initial_cell,\n",
    "                                    np.squeeze(MASK))\n",
    "    collections.append(collection)\n",
    "    end_loop = time.time()\n",
    "    print(f'Loop completed in {end_loop - begin_loop}')\n",
    "end = time.time()\n",
    "#     plot_sis_collection(initial_image, collection, FULLY_MASKED_IMAGE)\n",
    "print(f'Cell complete in {end-begin} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIS Output Analysis\n",
    "Each SIS Output comes as an interable of length 4 with the following entries:\n",
    "0. sis: Sufficient input subset, ordered by most important features\n",
    "1. The order of features removed by back selection -- the most important features are at the end\n",
    "2. The resulting probabilities if you remove up to that feature\n",
    "3. Mask (probably not important for this analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "____________________________________________________________________________________________________\n",
      "Dataset: RNA Raw\n",
      "Num cells above threshold : 103\n",
      "Important features to classify as 3hr\n",
      "{}\n",
      "____________________________________________________________________________________________________\n",
      "Cell 0 Disjoint SIS: []\n",
      "Cell 1 Disjoint SIS: []\n",
      "Cell 2 Disjoint SIS: []\n",
      "Cell 3 Disjoint SIS: []\n",
      "Cell 4 Disjoint SIS: []\n",
      "Cell 5 Disjoint SIS: []\n",
      "Cell 6 Disjoint SIS: []\n",
      "Cell 7 Disjoint SIS: []\n",
      "Cell 8 Disjoint SIS: []\n",
      "Cell 9 Disjoint SIS: []\n",
      "Cell 10 Disjoint SIS: []\n",
      "Cell 11 Disjoint SIS: []\n",
      "Cell 12 Disjoint SIS: []\n",
      "Cell 13 Disjoint SIS: []\n",
      "Cell 14 Disjoint SIS: []\n",
      "Cell 15 Disjoint SIS: []\n",
      "Cell 16 Disjoint SIS: []\n",
      "Cell 17 Disjoint SIS: []\n",
      "Cell 18 Disjoint SIS: []\n",
      "Cell 19 Disjoint SIS: []\n",
      "Cell 20 Disjoint SIS: []\n",
      "Cell 21 Disjoint SIS: []\n",
      "Cell 22 Disjoint SIS: []\n",
      "Cell 23 Disjoint SIS: []\n",
      "Cell 24 Disjoint SIS: []\n",
      "Cell 25 Disjoint SIS: []\n",
      "Cell 26 Disjoint SIS: []\n",
      "Cell 27 Disjoint SIS: []\n",
      "Cell 28 Disjoint SIS: []\n",
      "Cell 29 Disjoint SIS: []\n",
      "Cell 30 Disjoint SIS: []\n",
      "Cell 31 Disjoint SIS: []\n",
      "Cell 32 Disjoint SIS: []\n",
      "Cell 33 Disjoint SIS: []\n",
      "Cell 34 Disjoint SIS: []\n",
      "Cell 35 Disjoint SIS: []\n",
      "Cell 36 Disjoint SIS: []\n",
      "Cell 37 Disjoint SIS: []\n",
      "Cell 38 Disjoint SIS: []\n",
      "Cell 39 Disjoint SIS: []\n",
      "Cell 40 Disjoint SIS: []\n",
      "Cell 41 Disjoint SIS: []\n",
      "Cell 42 Disjoint SIS: []\n",
      "Cell 43 Disjoint SIS: []\n",
      "Cell 44 Disjoint SIS: []\n",
      "Cell 45 Disjoint SIS: []\n",
      "Cell 46 Disjoint SIS: []\n",
      "Cell 47 Disjoint SIS: []\n",
      "Cell 48 Disjoint SIS: []\n",
      "Cell 49 Disjoint SIS: []\n",
      "Cell 50 Disjoint SIS: []\n",
      "Cell 51 Disjoint SIS: []\n",
      "Cell 52 Disjoint SIS: []\n",
      "Cell 53 Disjoint SIS: []\n",
      "Cell 54 Disjoint SIS: []\n",
      "Cell 55 Disjoint SIS: []\n",
      "Cell 56 Disjoint SIS: []\n",
      "Cell 57 Disjoint SIS: []\n",
      "Cell 58 Disjoint SIS: []\n",
      "Cell 59 Disjoint SIS: []\n",
      "Cell 60 Disjoint SIS: []\n",
      "Cell 61 Disjoint SIS: []\n",
      "Cell 62 Disjoint SIS: []\n",
      "Cell 63 Disjoint SIS: []\n",
      "Cell 64 Disjoint SIS: []\n",
      "Cell 65 Disjoint SIS: []\n",
      "Cell 66 Disjoint SIS: []\n",
      "Cell 67 Disjoint SIS: []\n",
      "Cell 68 Disjoint SIS: []\n",
      "Cell 69 Disjoint SIS: []\n",
      "Cell 70 Disjoint SIS: []\n",
      "Cell 71 Disjoint SIS: []\n",
      "Cell 72 Disjoint SIS: []\n",
      "Cell 73 Disjoint SIS: []\n",
      "Cell 74 Disjoint SIS: []\n",
      "Cell 75 Disjoint SIS: []\n",
      "Cell 76 Disjoint SIS: []\n",
      "Cell 77 Disjoint SIS: []\n",
      "Cell 78 Disjoint SIS: []\n",
      "Cell 79 Disjoint SIS: []\n",
      "Cell 80 Disjoint SIS: []\n",
      "Cell 81 Disjoint SIS: []\n",
      "Cell 82 Disjoint SIS: []\n",
      "Cell 83 Disjoint SIS: []\n",
      "Cell 84 Disjoint SIS: []\n",
      "Cell 85 Disjoint SIS: []\n",
      "Cell 86 Disjoint SIS: []\n",
      "Cell 87 Disjoint SIS: []\n",
      "Cell 88 Disjoint SIS: []\n",
      "Cell 89 Disjoint SIS: []\n",
      "Cell 90 Disjoint SIS: []\n",
      "Cell 91 Disjoint SIS: []\n",
      "Cell 92 Disjoint SIS: []\n",
      "Cell 93 Disjoint SIS: []\n",
      "Cell 94 Disjoint SIS: []\n",
      "Cell 95 Disjoint SIS: []\n",
      "Cell 96 Disjoint SIS: []\n",
      "Cell 97 Disjoint SIS: []\n",
      "Cell 98 Disjoint SIS: []\n",
      "Cell 99 Disjoint SIS: []\n",
      "Cell 100 Disjoint SIS: []\n",
      "Cell 101 Disjoint SIS: []\n",
      "Cell 102 Disjoint SIS: []\n"
     ]
    }
   ],
   "source": [
    "# Analyze collections\n",
    "def get_features_from_ixs(ix, feature_vec):\n",
    "    return feature_vec[ix].to_numpy()\n",
    "\n",
    "\n",
    "# Get all subsets into a nice dataframe\n",
    "def get_features_from_collection(collection, feature_vec):\n",
    "    features_mat = []\n",
    "    for ix, cell in enumerate(collection):\n",
    "        for disjoint_subset in cell:\n",
    "            sis_ixs = disjoint_subset[0]\n",
    "            features = get_features_from_ixs(sis_ixs, feature_vec)\n",
    "            features_mat.append((ix, features))\n",
    "    return features_mat\n",
    "\n",
    "\n",
    "# get a list of most important features\n",
    "important_features = get_features_from_collection(collections, FEATURE_VEC)\n",
    "\n",
    "def count_genes(important_features):\n",
    "    gene_dict = {}\n",
    "    for ix, features in important_features:\n",
    "        for f in features:\n",
    "            if f[0] not in gene_dict:\n",
    "                gene_dict[f[0]] = 1\n",
    "            else:\n",
    "                gene_dict[f[0]] += 1\n",
    "    # sort gene dict\n",
    "    \n",
    "    return gene_dict\n",
    "\n",
    "gene_dict = count_genes(important_features)\n",
    "\n",
    "classes = ['0hr', '1hr', '3hr']\n",
    "\n",
    "def print_features(important_features, class_, dataset):\n",
    "    print('_'*100)\n",
    "    print(f'Dataset: {dataset}')\n",
    "    print(f'Num cells above threshold : {len(cells_to_run_sis)}')\n",
    "    print(f'Important features to classify as {class_}')\n",
    "    print(count_genes(important_features))\n",
    "    print('_'*100)\n",
    "    for row in important_features:\n",
    "        print(f'Cell {row[0]} Disjoint SIS: {[g[0] for g in row[1]]}')\n",
    "        \n",
    "\n",
    "# get an ordered list of the importance of each feature, ordered by fraction of cells the feature appears in\n",
    "def order_features(gene_dict, num_confident_cells):\n",
    "    feature_list = []\n",
    "    for feature, count in gene_dict.items():\n",
    "        feature_list.append((feature, count/num_confident_cells))\n",
    "    # sort by number of appearances\n",
    "    sorted_features = sorted(feature_list, key=lambda x: x[1], reverse=True)\n",
    "    return sorted_features\n",
    "#     # cast as DataFrame\n",
    "#     return pd.DataFrame()\n",
    "\n",
    "# print(f'{line}\\n' for line in order_features(gene_dict, len(cells_to_run_sis)))\n",
    "features = order_features(gene_dict, len(cells_to_run_sis))\n",
    "print(features)\n",
    "\n",
    "# get a print out of the important features\n",
    "print_features(important_features, class_=classes[HOURS], dataset=TITLE)\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(features, columns=['Feature','% occurrence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>% occurrence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Feature, % occurrence]\n",
       "Index: []"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_zipped_pickle(data, filename=os.path.join(root, 'results', 'SIS', f'{TITLE}_class_{HOURS}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return sorted list of gene counts\n",
    "# data = count_genes(important_features), important_features\n",
    "# write_zipped_pickle(data, filename=os.path.join(root, 'results', 'initial_model_pp_fs_scai', f'ATAC_SVD_{classes[HOURS]}_SIS_thresh={THRESHOLD}.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Reference code from Google Research -- running SIS on MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Select a digit and threshold {run: \"auto\"}\n",
    "\n",
    "DIGIT = 4  #@param ['0', 1', '2', '3', '4', '5', '6', '7', '8', '9'] {type:\"raw\"}\n",
    "\n",
    "THRESHOLD = 0.7  #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
    "\n",
    "# Following the SIS paper, we use the mean pixel from training images as a mask.\n",
    "FULLY_MASKED_IMAGE = np.full((28, 28, 1), np.mean(x_train))\n",
    "\n",
    "# Helper function that selects the probability for a single class, from the\n",
    "# softmax output.\n",
    "def make_f_for_digit(digit, model):\n",
    "    def f_digit(batch_of_inputs):\n",
    "        return model.predict(\n",
    "            batch_of_inputs,\n",
    "            batch_size=min(784, len(batch_of_inputs)))[:, digit]\n",
    "    return f_digit\n",
    "\n",
    "# This function maps a list of images to a list of probabilities (probability of\n",
    "# each image being a 4).\n",
    "f_digit = make_f_for_digit(DIGIT, model)\n",
    "\n",
    "# Helper function that filters input images to those the model predicts with\n",
    "# high confidence (f(image) >= threshold).\n",
    "def select_images_for_sis(inputs, f_digit, threshold):\n",
    "    preds = f_digit(inputs)\n",
    "    idxs = np.nonzero(preds >= threshold)[0]\n",
    "    return inputs[idxs]\n",
    "\n",
    "# Filter test images that the model classifies as 4 with high confidence.\n",
    "high_confidence_images_for_digit = select_images_for_sis(x_test, f_digit,\n",
    "                                                         THRESHOLD)\n",
    "\n",
    "# Randomly select some of these digits to run SIS.\n",
    "digits_to_run_sis = high_confidence_images_for_digit[\n",
    "    np.random.choice(high_confidence_images_for_digit.shape[0],\n",
    "                     size=5,\n",
    "                     replace=False)]\n",
    "\n",
    "# Helpers for plotting an MNIST digit and its corresponding SIS-collection.\n",
    "def plot_mnist_digit(ax, image):\n",
    "    ax.imshow(image[:, :, 0], cmap=plt.get_cmap('gray'))\n",
    "    ax.axis('off')\n",
    "\n",
    "def plot_sis_collection(initial_image, collection, fully_masked_image):\n",
    "    # Grid contains initial image, an empty cell (for spacing), and collection.\n",
    "    width = len(collection) + 2\n",
    "    plt.figure(figsize=(width, 1))\n",
    "    gs = plt.GridSpec(1, width, wspace=0.1)\n",
    "\n",
    "    # Plot initial image.\n",
    "    ax = plt.subplot(gs[0])\n",
    "    plot_mnist_digit(ax, initial_image)\n",
    "\n",
    "    # Plot each SIS.\n",
    "    for i, sis_result in enumerate(collection):\n",
    "        ax = plt.subplot(gs[i+2])\n",
    "        masked_image = sis.produce_masked_inputs(\n",
    "            initial_image, fully_masked_image, [sis_result.mask])[0]\n",
    "        plot_mnist_digit(ax, masked_image)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "print('Running SIS on {} examples of digit {}. '\n",
    "      'This might take a couple minutes.'.format(len(digits_to_run_sis), DIGIT))\n",
    "\n",
    "# Run SIS on each digit and visualize the resulting SIS-collections.\n",
    "for initial_image in digits_to_run_sis:\n",
    "    collection = sis.sis_collection(f_digit, THRESHOLD, initial_image,\n",
    "                                    FULLY_MASKED_IMAGE)\n",
    "    plot_sis_collection(initial_image, collection, FULLY_MASKED_IMAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
